 147 -     retrieved_docs = mock_retrieve_documents(query)                                                         ││ 148 -     logging.info(f"Retrieved {len(retrieved_docs)} documents.")                                             ││  87 +     # Get user's name from their profile, with a default                                                    ││  88 +     user_name = user_profile.get("name", "there")                                                           ││  89                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 150 -     if not retrieved_docs:                                                                                  ││ 151 -         return "I couldn't find relevant information in my knowledge base to answer that."                  ││  90 +     # Get preferred tone, with a default                                                                    ││  91 +     bot_personality = user_profile.get("preferred_tone", "a helpful assistant")                             ││  92                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 153 -     # 2. Generate RAG-specific prompt                                                                       ││ 154 -     rag_prompt = generate_rag_prompt(query, retrieved_docs)                                                 ││  93 +     prompt = f"""                                                                                           ││  94 + You are {bot_personality}. The user's name is {user_name}.                                                  ││  95 + A user has asked a question. Using ONLY the following text, please answer the user's question.              ││  96 + Address the user by their name in your response.                                                            ││  97                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 156 -     # 3. Use GeminiModel to generate the answer                                                             ││ 157 -     try:                                                                                                    ││ 158 -         final_answer = gemini_client.call(rag_prompt)                                                       ││ 159 -         return final_answer                                                                                 ││ 160 -     except Exception as e:                                                                                  ││ 161 -         logging.error(f"Error generating answer with GeminiModel: {e}")                                     ││ 162 -         return "An error occurred while generating the answer."                                             ││  98 + ---                                                                                                         ││  99 + TEXT:                                                                                                       ││ 100 + {context}                                                                                                   ││ 101 + ---                                                                                                         ││ 102                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 164 - if __name__ == "__main__":                                                                                  ││ 165 -     # Initialize our Gemini client                                                                          ││ 166 -     # Using 'gemini-pro' for general purpose, ensure your API key supports it                               ││ 167 -     gemini_client = GeminiModel(model_name="gemini-pro", temperature=0.0)                                   ││ 103 + QUESTION:                                                                                                   ││ 104 + {question}                                                                                                  ││ 105 + """                                                                                                         ││ 106                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 169 -     print("\n--- Testing RAG System ---")                                                                   ││ 170 -     user_query = "What is Spec-Driven Development?"                                                         ││ 171 -     print(f"User Query: {user_query}")                                                                      ││ 172 -     answer = simple_rag_system(user_query, gemini_client)                                                   ││ 173 -     print(f"RAG System Answer: {answer}")                                                                   ││ 107 +     # ... (call GeminiModel and store conversation history as before) ...                                   ││ 108                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 175 -     print("\n--- Testing RAG System with another query ---")                                                ││ 176 -     user_query_2 = "How does the GeminiModel class work?"                                                   ││ 177 -     print(f"User Query: {user_query_2}")                                                                    ││ 178 -     answer_2 = simple_rag_system(user_query_2, gemini_client)                                               ││ 179 -     print(f"RAG System Answer: {answer_2}")                                                                 ││ 109 +     answer = gemini_model.call(prompt=prompt)                                                               ││ 110                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 181 -     print("\n--- Testing RAG System with a query outside context ---")                                      ││ 182 -     user_query_3 = "What is the capital of Japan?"                                                          ││ 183 -     print(f"User Query: {user_query_3}")                                                                    ││ 184 -     answer_3 = simple_rag_system(user_query_3, gemini_client)                                               ││ 185 -     print(f"RAG System Answer: {answer_3}")                                                                 ││ 111 +     # You could also update the user profile here, e.g., by saving the topic.                               ││ 112 +     # db.update_user_profile(user_profile.id, {"last_topic": "some_topic"})                                 ││ 113                                                                                                               ││ 114 +     return answer, new_conversation_id                                                                      ││ 115   ```                                                                                                         ││ 116                                                                                                               ││ 117 + By making this small change, our chatbot is transformed. Instead of a generic "You," it can now say, "Hi    ││     Alex, I found this information for you..." This simple act of personalization dramatically improves the user  ││     experience, making the application feel more like a personal assistant.                                       ││ 118 +                                                                                                             ││ 119   ## What's Next?                                                                                             ││ 120                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 191 - You've successfully built a foundational RAG system! While our retriever is currently mocked, this chapter  ││     demonstrates the core interaction between finding relevant information and using a powerful LLM to synthesize ││     an answer.                                                                                                    ││ 121 + We've added a crucial layer to our application, enabling us to build a relationship with our users. With    ││     authentication and personalization in place, we're ready to start thinking about the user interface.          ││ 122                                                                                                               ││ ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════ ││ 193 - In the next chapters, we'll explore how to build a more robust retriever, potentially using vector          ││     databases and more sophisticated indexing techniques, and how to deploy our RAG system as a functional API.   ││ 123 + In the next chapter, we'll shift our focus from the backend to the frontend. We'll explore how to build a   ││     responsive and intuitive web interface for our chatbot using a modern JavaScript framework, allowing users to ││     interact with the powerful system we've just built.                                                           